# -*- coding: utf-8 -*-
"""Model2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1re-dh3zI9x5LOvF0fRjezKZMhOBSlVFf
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split

def train_neural_network(x, y, test_size=0.2, random_state=42):
    # Split the data into training and testing sets
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)
    
    # Set the random seed for reproducibility
    tf.random.set_seed(42)

    # Build the neural network model
    model = Sequential([
        Dense(100, activation=tf.keras.activations.relu),
        tf.keras.layers.Dropout(0.2),
        Dense(50, activation=tf.keras.activations.relu),
        Dense(40, activation=tf.keras.activations.relu),
        tf.keras.layers.Dropout(0.2),
        Dense(32, activation=tf.keras.activations.relu),
        Dense(16, activation=tf.keras.activations.relu),
        Dense(8, activation=tf.keras.activations.relu),
        Dense(1, activation='sigmoid')
    ])
    
    # Compile the model with the binary cross-entropy loss and Adam optimizer
    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])

    # Fit the model to the training data and store the training history
    history = model.fit(x_train, y_train, epochs=500)
    
    return model, history